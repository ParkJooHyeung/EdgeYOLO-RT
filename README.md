# ğŸš€ EdgeYOLO-RT: ì´ˆê²½ëŸ‰ ì‹¤ì‹œê°„ ì•ˆì „ ê°ì§€ ì‹œìŠ¤í…œ
> **High-Performance Object Detection Inference Engine using TensorRT & C++**

![C++](https://img.shields.io/badge/C++-17-blue?logo=c%2B%2B)
![TensorRT](https://img.shields.io/badge/NVIDIA-TensorRT-green?logo=nvidia)
![OpenCV](https://img.shields.io/badge/OpenCV-4.x-red?logo=opencv)
![YOLOv8](https://img.shields.io/badge/Model-YOLOv8-yellow)

## ğŸ“– 1. Project Overview (í”„ë¡œì íŠ¸ ê°œìš”)
ë³¸ í”„ë¡œì íŠ¸ëŠ” **ì„ë² ë””ë“œ/ì—£ì§€ í™˜ê²½**ì—ì„œì˜ ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ë¥¼ ìœ„í•´, ê¸°ì¡´ Python/PyTorch ê¸°ë°˜ì˜ YOLOv8 ëª¨ë¸ì„ **C++ì™€ TensorRT**ë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì í™”í•œ ì¶”ë¡  ì—”ì§„ êµ¬í˜„ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

ì‚°ì—… í˜„ì¥ì˜ ì•ˆì „ ëª¨ë‹ˆí„°ë§(ì•ˆì „ëª¨ ë¯¸ì°©ìš©, ìœ„í—˜ êµ¬ì—­ ì¹¨ë²” ë“±)ì„ ê°€ì •í•˜ì—¬, ì œí•œëœ í•˜ë“œì›¨ì–´ ìì› ë‚´ì—ì„œ **FPS(ì´ˆë‹¹ í”„ë ˆì„)ë¥¼ ê·¹ëŒ€í™”**í•˜ê³  **GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ìµœì†Œí™”**í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ì˜€ìŠµë‹ˆë‹¤.

### **ğŸ¯ Key Achievements**
- **ì†ë„ í–¥ìƒ:** Python(PyTorch) ëŒ€ë¹„ **ì•½ 3ë°° ê°€ì†** (30 FPS â†’ **95 FPS**)
- **ë©”ëª¨ë¦¬ ìµœì í™”:** **INT8 Quantization** ì ìš©ì„ í†µí•´ ëª¨ë¸ ì‚¬ì´ì¦ˆ **4ë°° ê°ì†Œ** ë° ëŸ°íƒ€ì„ ë©”ëª¨ë¦¬ ì ˆê°
- **Low-Level êµ¬í˜„:** Python ì¢…ì†ì„±ì„ ì œê±°í•˜ê³ , **CUDA Memory Management** ë° **NMS(Non-Maximum Suppression)** ì•Œê³ ë¦¬ì¦˜ì„ C++ë¡œ ì§ì ‘ êµ¬í˜„

---

## ğŸ“Š 2. Performance Benchmark (ì„±ëŠ¥ ë¶„ì„)
> *Tested on NVIDIA GeForce RTX 3060 Laptop GPU / Input Resolution: 640x640*

### **âš¡ Inference Speed & Memory Usage**
ê°€ì¥ ì¤‘ìš”í•œ ìµœì í™” ì„±ê³¼ ì§€í‘œì…ë‹ˆë‹¤. TensorRT FP16 ë° INT8 ì ìš© ì‹œì˜ ì„±ëŠ¥ ë³€í™”ë¥¼ ë¹„êµí–ˆìŠµë‹ˆë‹¤.

| Environment | Precision | Latency (ms) | Throughput (FPS) | GPU Memory (MB) | Improvement |
|:---:|:---:|:---:|:---:|:---:|:---:|
| **Python (PyTorch)** | FP32 | 33.2 ms | 30.1 FPS | 1,250 MB | Baseline |
| **C++ (TensorRT)** | FP16 | 12.5 ms | 80.0 FPS | 850 MB | **2.6x Faster** |
| **C++ (TensorRT)** | **INT8** | **10.5 ms** | **95.2 FPS** | **620 MB** | **3.1x Faster** |

![Benchmark Graph](https://via.placeholder.com/800x400?text=Insert+Performance+Graph+Here)

---

## ğŸ›  3. Technical Highlights (ê¸°ìˆ ì  í•µì‹¬ ë‚´ìš©)

### **A. TensorRT Engine Optimization**
- **ONNX Parsing:** PyTorch(`ultralytics`) ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜ í›„, `trtexec` ë° C++ APIë¥¼ í†µí•´ ì—”ì§„ ë¹Œë“œ.
- **Precision Calibration:** FP16(Half Precision) ë° INT8 ì–‘ìí™”ë¥¼ ì ìš©í•˜ì—¬ ì—°ì‚° íš¨ìœ¨ ì¦ëŒ€.
- **Dynamic Shapes:** ê³ ì •ëœ Input Dimensionì„ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ ì¬í• ë‹¹ ì˜¤ë²„í—¤ë“œ ì œê±°.

### **B. Efficient Memory Management (C++ & CUDA)**
- **Buffer Reuse:** ë§¤ í”„ë ˆì„ë§ˆë‹¤ `cudaMalloc`ì„ í˜¸ì¶œí•˜ì§€ ì•Šê³ , ì´ˆê¸°í™” ë‹¨ê³„ì—ì„œ Input/Output Device ë©”ëª¨ë¦¬ë¥¼ í•œ ë²ˆë§Œ í• ë‹¹í•˜ì—¬ ì¬ì‚¬ìš©.
- **Zero-Copy Consideration:** Host(CPU)ì™€ Device(GPU) ê°„ì˜ ë°ì´í„° ì „ì†¡(`cudaMemcpy`) ìµœì†Œí™” ì „ëµ ìˆ˜ë¦½.

### **C. Custom Post-Processing**
- YOLOv8ì˜ Output Tensor êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ Decoding ë¡œì§ êµ¬í˜„.
- **NMS(Non-Maximum Suppression)** ì•Œê³ ë¦¬ì¦˜ì„ C++ `std::sort`ì™€ `IoU` ê³„ì‚° í•¨ìˆ˜ë¡œ ì§ì ‘ êµ¬í˜„í•˜ì—¬ ì¤‘ë³µ ë°•ìŠ¤ ì œê±° ìµœì í™”.

---

## ğŸ’» 4. Environment & Prerequisites

### **H/W & S/W Requirements**
# ğŸš€ EdgeYOLO-RT: ì´ˆê²½ëŸ‰ ì‹¤ì‹œê°„ ì•ˆì „ ê°ì§€ ì‹œìŠ¤í…œ
> **High-Performance Object Detection Inference Engine using TensorRT & C++**

![C++](https://img.shields.io/badge/C++-17-blue?logo=c%2B%2B)
![TensorRT](https://img.shields.io/badge/NVIDIA-TensorRT-green?logo=nvidia)
![OpenCV](https://img.shields.io/badge/OpenCV-4.x-red?logo=opencv)
![YOLOv8](https://img.shields.io/badge/Model-YOLOv8-yellow)

## ğŸ“– 1. Project Overview (í”„ë¡œì íŠ¸ ê°œìš”)
ë³¸ í”„ë¡œì íŠ¸ëŠ” **ì„ë² ë””ë“œ/ì—£ì§€ í™˜ê²½**ì—ì„œì˜ ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ë¥¼ ìœ„í•´, ê¸°ì¡´ Python/PyTorch ê¸°ë°˜ì˜ YOLOv8 ëª¨ë¸ì„ **C++ì™€ TensorRT**ë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì í™”í•œ ì¶”ë¡  ì—”ì§„ êµ¬í˜„ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

ì‚°ì—… í˜„ì¥ì˜ ì•ˆì „ ëª¨ë‹ˆí„°ë§(ì•ˆì „ëª¨ ë¯¸ì°©ìš©, ìœ„í—˜ êµ¬ì—­ ì¹¨ë²” ë“±)ì„ ê°€ì •í•˜ì—¬, ì œí•œëœ í•˜ë“œì›¨ì–´ ìì› ë‚´ì—ì„œ **FPS(ì´ˆë‹¹ í”„ë ˆì„)ë¥¼ ê·¹ëŒ€í™”**í•˜ê³  **GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ìµœì†Œí™”**í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ì˜€ìŠµë‹ˆë‹¤.

### **ğŸ¯ Key Achievements**
- **ì†ë„ í–¥ìƒ:** Python(PyTorch) ëŒ€ë¹„ **ì•½ 3ë°° ê°€ì†** (30 FPS â†’ **95 FPS**)
- **ë©”ëª¨ë¦¬ ìµœì í™”:** **INT8 Quantization** ì ìš©ì„ í†µí•´ ëª¨ë¸ ì‚¬ì´ì¦ˆ **4ë°° ê°ì†Œ** ë° ëŸ°íƒ€ì„ ë©”ëª¨ë¦¬ ì ˆê°
- **Low-Level êµ¬í˜„:** Python ì¢…ì†ì„±ì„ ì œê±°í•˜ê³ , **CUDA Memory Management** ë° **NMS(Non-Maximum Suppression)** ì•Œê³ ë¦¬ì¦˜ì„ C++ë¡œ ì§ì ‘ êµ¬í˜„

---

## ğŸ“Š 2. Performance Benchmark (ì„±ëŠ¥ ë¶„ì„)
> *Tested on NVIDIA GeForce RTX 3060 Laptop GPU / Input Resolution: 640x640*

### **âš¡ Inference Speed & Memory Usage**
ê°€ì¥ ì¤‘ìš”í•œ ìµœì í™” ì„±ê³¼ ì§€í‘œì…ë‹ˆë‹¤. TensorRT FP16 ë° INT8 ì ìš© ì‹œì˜ ì„±ëŠ¥ ë³€í™”ë¥¼ ë¹„êµí–ˆìŠµë‹ˆë‹¤.

| Environment | Precision | Latency (ms) | Throughput (FPS) | GPU Memory (MB) | Improvement |
|:---:|:---:|:---:|:---:|:---:|:---:|
| **Python (PyTorch)** | FP32 | 33.2 ms | 30.1 FPS | 1,250 MB | Baseline |
| **C++ (TensorRT)** | FP16 | 12.5 ms | 80.0 FPS | 850 MB | **2.6x Faster** |
| **C++ (TensorRT)** | **INT8** | **10.5 ms** | **95.2 FPS** | **620 MB** | **3.1x Faster** |

![Benchmark Graph](https://via.placeholder.com/800x400?text=Insert+Performance+Graph+Here)

---

## ğŸ›  3. Technical Highlights (ê¸°ìˆ ì  í•µì‹¬ ë‚´ìš©)

### **A. TensorRT Engine Optimization**
- **ONNX Parsing:** PyTorch(`ultralytics`) ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜ í›„, `trtexec` ë° C++ APIë¥¼ í†µí•´ ì—”ì§„ ë¹Œë“œ.
- **Precision Calibration:** FP16(Half Precision) ë° INT8 ì–‘ìí™”ë¥¼ ì ìš©í•˜ì—¬ ì—°ì‚° íš¨ìœ¨ ì¦ëŒ€.
- **Dynamic Shapes:** ê³ ì •ëœ Input Dimensionì„ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ ì¬í• ë‹¹ ì˜¤ë²„í—¤ë“œ ì œê±°.

### **B. Efficient Memory Management (C++ & CUDA)**
- **Buffer Reuse:** ë§¤ í”„ë ˆì„ë§ˆë‹¤ `cudaMalloc`ì„ í˜¸ì¶œí•˜ì§€ ì•Šê³ , ì´ˆê¸°í™” ë‹¨ê³„ì—ì„œ Input/Output Device ë©”ëª¨ë¦¬ë¥¼ í•œ ë²ˆë§Œ í• ë‹¹í•˜ì—¬ ì¬ì‚¬ìš©.
- **Zero-Copy Consideration:** Host(CPU)ì™€ Device(GPU) ê°„ì˜ ë°ì´í„° ì „ì†¡(`cudaMemcpy`) ìµœì†Œí™” ì „ëµ ìˆ˜ë¦½.

### **C. Custom Post-Processing**
- YOLOv8ì˜ Output Tensor êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ Decoding ë¡œì§ êµ¬í˜„.
- **NMS(Non-Maximum Suppression)** ì•Œê³ ë¦¬ì¦˜ì„ C++ `std::sort`ì™€ `IoU` ê³„ì‚° í•¨ìˆ˜ë¡œ ì§ì ‘ êµ¬í˜„í•˜ì—¬ ì¤‘ë³µ ë°•ìŠ¤ ì œê±° ìµœì í™”.

---

## ğŸ’» 4. Environment & Prerequisites

### **H/W & S/W Requirements**
* **OS:** Ubuntu 20.04 LTS
* **Compiler:** GCC 9.4.0 / CMake 3.10+
* **CUDA:** 11.8
* **TensorRT:** 8.6.1
* **OpenCV:** 4.5.5 (w/ contrib)

---

## ğŸš€ 5. How to Run (ì‹¤í–‰ ë°©ë²•)

### **Step 1: Convert Model (Python)**
PyTorch ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
```bash
cd python
pip install ultralytics
python export.py --weights yolov8s.pt --dest model.onnx
```